{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DiSxm5YI_fd"
   },
   "source": [
    "# Convolutions\n",
    "\n",
    "In this lab, we'll look in detail at convolutions and how they can be used to process images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRbOkblrI_fe"
   },
   "source": [
    "### Reading and opening images\n",
    "\n",
    "We'll use the `skimage` library to read and process images. It's a library dedicated to image processing, which is part of the `scikit-learn` family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKDUIG0oI_fe"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "p351aOgAI_fe",
    "outputId": "ffe85424-b3f4-4a4a-ab52-21020343c8a6"
   },
   "outputs": [],
   "source": [
    "sample_image = skimage.data.coffee()\n",
    "\n",
    "size = sample_image.shape\n",
    "print(\"sample image shape: \", sample_image.shape)\n",
    "\n",
    "plt.imshow(sample_image.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPUPPLODI_ff"
   },
   "source": [
    "### A simple convolution filter\n",
    "\n",
    "Before we start working on training any models, let's look at applying a convolution filter to an image. We'll use the `Conv2D` layer from Keras to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b84P4d3RI_ff"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GFxBzDrI_ff",
    "outputId": "2317db85-b5ed-478a-9ccc-9857fd0ae703",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "              input_shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNgB-tWCI_ff"
   },
   "source": [
    "Remember: in Keras, `None` is used as a marker for tensor dimensions with dynamic size. In this case `batch_size`, `width` and `height` are all dynamic: they can depend on the input. This is a neat feature of convolutional neural networks: the same model can be used to process images of any size, because all we have to do is slide the convolutional filter across the image as much as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsvzRP4_I_ff",
    "outputId": "37576a35-734c-48ab-9f1a-4fd6ee1db563"
   },
   "outputs": [],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsLMyawzI_ff",
    "outputId": "772bf78c-2229-4385-92a3-2799bbd9ef86"
   },
   "outputs": [],
   "source": [
    "img_in = np.expand_dims(sample_image, 0).astype(float)\n",
    "img_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oInC5RVI_ff"
   },
   "outputs": [],
   "source": [
    "img_out = conv(img_in) # Apply the convolutional filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k01U8p1pI_ff"
   },
   "source": [
    "The output is a tensorflow Eager Tensor - a special data structure that is used to represent the result of operations in TensorFlow. It is not a numpy array, but it can be converted to one using the `.numpy()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYLQhj0I_ff",
    "outputId": "2ec97034-691c-4497-ae3a-41c666e9dd90"
   },
   "outputs": [],
   "source": [
    "np_img_out = img_out[0].numpy()\n",
    "print(type(np_img_out))\n",
    "print(np_img_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "dUXOccNiI_ff",
    "outputId": "13ad6dc4-2522-4c1e-ab06-a0677d5aeaed"
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(sample_image.astype('uint8'))\n",
    "ax1.imshow(np_img_out.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeqbA2ANI_ff"
   },
   "source": [
    "As we can see, our convolutional filter was initialized randomly, so our output doesn't contain any specific meaning. Each pixel is a random combination of the pixels in the input image, in a 5x5 window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrCsXsvWI_ff"
   },
   "source": [
    "Let's instead take a look at a convolutional feature with a clear purpose. We can build a kernel ourselves, by defining a function which will be passed to `Conv2D` Layer.\n",
    "We'll create an array with 1/25 for filters, with each channel seperated. Before you move to the next cell, can you guess what this filter will do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gZoFrfrI_ff"
   },
   "outputs": [],
   "source": [
    "def my_kernel(shape=(5, 5, 3, 3), dtype=None):\n",
    "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "    array[:, :, 0, 0] = 1 / 25\n",
    "    array[:, :, 1, 1] = 1 / 25\n",
    "    array[:, :, 2, 2] = 1 / 25\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "8q1FoYTKI_ff"
   },
   "source": [
    "Now we can use this function to initialize a `Conv2D` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ppP9rWEI_ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=my_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Rek1Cx4eI_ff",
    "outputId": "850b1656-73be-42ec-bb1f-3438a33b52ea"
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IemHFOdTI_ff"
   },
   "source": [
    "Hopefully you can tell what this filter does!\n",
    "\n",
    "**Exercise**\n",
    "- There are a number of settings when we define our Conv2D layer. Try changing the following parameters to get a sense of how they impact the result:\n",
    "- kernel_size: try different sizes\n",
    "- padding: try 'valid' instead of 'same' (hint: this may change the size of the output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88HzHNdLI_fg"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "\n",
    "# Define the custom kernel initializer\n",
    "class CustomKernelInitializer(Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "        array[:, :, 0, 0] = 1 / 25\n",
    "        array[:, :, 1, 1] = 1 / 25\n",
    "        array[:, :, 2, 2] = 1 / 25\n",
    "        return array\n",
    "    \n",
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"valid\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=CustomKernelInitializer)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel size: (5, 5), Padding: 'valid'\")\n",
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"valid\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=CustomKernelInitializer)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel size: (5, 5), Padding: 'same'\")\n",
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=CustomKernelInitializer)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel size: (3, 3), Padding: 'same'\")\n",
    "conv = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=CustomKernelInitializer)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel size: (3, 3), Padding: 'valid'\")\n",
    "conv = Conv2D(filters=3, kernel_size=(3, 3), padding=\"valid\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=CustomKernelInitializer)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "332KBYJGI_fg"
   },
   "source": [
    "### Working on edge detection on Grayscale image\n",
    "\n",
    "Using a grayscale image, let's build an \"edge detector\" using a convolutional filter. Some filters pre-date the deep learning era and are still used today. For example, the Sobel filter is used to detect edges in images. These easy-to-compute filters were used in the early days of computer vision and are still useful now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "u1kyMbN0I_fg",
    "outputId": "c2d1cb60-4ccb-4a4d-bce6-0c63a7035eb0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert image to greyscale\n",
    "grey_sample_image = sample_image.mean(axis=2)\n",
    "\n",
    "# add the channel dimension even if it's only one channel so\n",
    "# to be consistent with Keras expectations.\n",
    "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
    "\n",
    "# matplotlib does not like the extra dim for the color channel\n",
    "# when plotting gray-level images. Let's use squeeze:\n",
    "plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
    "           cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy3m-R1UI_fg"
   },
   "source": [
    "**Exercise**\n",
    "- Build an edge detector using `Conv2D` on greyscale image by defining the kernel inside `my_kernel`.\n",
    "- You may experiment with several kernels to find a way to detect edges. The following article contains specific examples of kernels that you can use:\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "- Try different kernels and see the impact on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "rWKOXeFZI_fg",
    "outputId": "34682b16-7184-49a4-dded-09625f9f8b0f"
   },
   "outputs": [],
   "source": [
    "def my_kernel(shape=(3, 3, 1, 1), dtype=None):\n",
    "    array = np.array([[-1, -1, -1],\n",
    "                      [-1,  8, -1],\n",
    "                      [-1, -1, -1]])\n",
    "    array = array.reshape(*shape)\n",
    "    return array\n",
    "\n",
    "conv = Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\",\n",
    "              input_shape=(None, None, 1), kernel_initializer=my_kernel)\n",
    "\n",
    "img_in = np.expand_dims(grey_sample_image, 0) # Reshape into a batch of size 1\n",
    "img_out = conv(img_in) # Apply the convolutional filter\n",
    "np_img_out = img_out[0].numpy() # Convert to numpy array\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
    "           cmap=plt.cm.gray)\n",
    "ax1.imshow(np_img_out.astype(np.uint8), cmap=plt.cm.gray);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom_kernel function for Sobel kernel\n",
    "def custom_kernel(shape=(3, 3, 1, 1), dtype=None):\n",
    "    array = np.array([[-1, -2, -1],\n",
    "                      [ 0,  0,  0],\n",
    "                      [ 1,  2,  1]])\n",
    "    array = array.reshape(*shape) # Reshape if needed\n",
    "    return array\n",
    "\n",
    "# Define a Conv2D layer with the custom Sobel kernel\n",
    "conv = Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\",\n",
    "              input_shape=(None, None, 1), kernel_initializer=custom_kernel)\n",
    "\n",
    "# Expand dimensions to match the input shape of the Conv2D layer\n",
    "img_in = np.expand_dims(grey_sample_image, 0)\n",
    "\n",
    "# Apply the convolutional filter\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "\n",
    "# Plot the original and convolved images\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(np.squeeze(grey_sample_image.astype(np.uint8)), cmap=plt.cm.gray)\n",
    "ax0.set_title('Original Image')\n",
    "ax1.imshow(np_img_out.astype(np.uint8), cmap=plt.cm.gray)\n",
    "ax1.set_title('Filtered Image\\nSobel Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyELlQJUI_fg"
   },
   "source": [
    "### Pooling and strides with convolutions\n",
    "\n",
    "**Exercise**\n",
    "- Use `MaxPool2D` to apply a 2x2 max pool with strides 2 to the image. What is the impact on the shape of the image?\n",
    "- Use `AvgPool2D` to apply an average pooling.\n",
    "- Is it possible to compute a max pooling and an average pooling with well chosen kernels?\n",
    "    Pooling layers like max pooling and average pooling help to simplify and emphasize the most important features in an image. Dedicated pooling layers are a simple and efficient way to do this compared to other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "6lIpi3BLI_fg",
    "outputId": "7ceeb020-4950-410c-df5d-c97bdb1a14b5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "\n",
    "# You can use `img_in` from above as input to the pooling layers\n",
    "\n",
    "plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
    "           cmap=plt.cm.gray);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "\n",
    "# Convert the image to greyscale (repeated for clarity)\n",
    "grey_sample_image = sample_image.mean(axis=2)\n",
    "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
    "\n",
    "# Expand dimensions to match the input shape of the pooling layers\n",
    "img_in = np.expand_dims(grey_sample_image, 0)\n",
    "\n",
    "# Apply 2x2 max pooling with strides of 2\n",
    "max_pool = MaxPool2D(pool_size=(2, 2), strides=2)\n",
    "max_pooled_img = max_pool(img_in)\n",
    "\n",
    "# Convert to numpy array and squeeze to remove the extra dimension\n",
    "np_max_pooled_img = np.squeeze(max_pooled_img[0].numpy())\n",
    "\n",
    "# Plot the original and max pooled images\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(np.squeeze(grey_sample_image.astype(np.uint8)), cmap=plt.cm.gray)\n",
    "ax0.set_title('Original Image')\n",
    "ax1.imshow(np_max_pooled_img.astype(np.uint8), cmap=plt.cm.gray)\n",
    "ax1.set_title('Max Pooled Image')\n",
    "plt.show()\n",
    "\n",
    "print(\"Original shape:\", grey_sample_image.shape)\n",
    "print(\"Max pooled shape:\", np_max_pooled_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 2x2 average pooling with strides of 2\n",
    "avg_pool = AvgPool2D(pool_size=(2, 2), strides=2)\n",
    "avg_pooled_img = avg_pool(img_in)\n",
    "\n",
    "# Convert to numpy array and squeeze to remove the extra dimension\n",
    "np_avg_pooled_img = np.squeeze(avg_pooled_img[0].numpy())\n",
    "\n",
    "# Plot the original and average pooled images\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(np.squeeze(grey_sample_image.astype(np.uint8)), cmap=plt.cm.gray)\n",
    "ax0.set_title('Original Image')\n",
    "ax1.imshow(np_avg_pooled_img.astype(np.uint8), cmap=plt.cm.gray)\n",
    "ax1.set_title('Average Pooled Image')\n",
    "plt.show()\n",
    "\n",
    "print(\"Original shape:\", grey_sample_image.shape)\n",
    "print(\"Average pooled shape:\", np_avg_pooled_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "dB0KFsq0I_fg"
   },
   "source": [
    "## Loading a JPEG file as a numpy array\n",
    "\n",
    "Let's use [scikit-image](http://scikit-image.rg) to load the content of a JPEG file into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "D21MAIc-I_fg",
    "outputId": "c259092e-da45-45e8-a2a3-9d9617865bbc"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "image = skimage.data.cat()\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "CcebsPFJI_fg"
   },
   "source": [
    "## Resizing images, handling data types and dynamic ranges\n",
    "\n",
    "While convolutions can handle inputs of any size, it is often useful to resize images to a fixed size. This is particularly important for training deep learning models:\n",
    "\n",
    "- for **image classification**, most networks expect a specific **fixed input size**;\n",
    "\n",
    "- for **object detection** and instance segmentation, networks have more flexibility but the image should have **approximately the same size as the training set images**.\n",
    "\n",
    "Furthermore **large images can be much slower to process** than smaller images (the number of pixels varies quadratically with the height and width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jul1uEtDI_fg",
    "outputId": "541d4ae9-b4b4-43de-8e84-f01627d07550"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "lowres_image = resize(image, (50, 50), mode='reflect', anti_aliasing=True)\n",
    "lowres_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "ZWqksDTmI_fg",
    "outputId": "1654a16c-230e-42b3-e246-183786b9ebf5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(lowres_image, interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "J66Ac0AJI_fg"
   },
   "source": [
    "The values of the pixels of the low resolution image are computed from by combining the values of the pixels in the high resolution image. The result is therefore represented as floating points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WM-SeE-TI_fg"
   },
   "source": [
    "## Using a pretrained model\n",
    "\n",
    "Objectives:\n",
    "\n",
    "- Load a pre-trained ResNet50 pre-trained model using Keras Zoo\n",
    "- Use the model to classify an image\n",
    "- Use the model to classify an image from the webcam\n",
    "\n",
    "Let's start with loading ResNet50, a well-established method for image classification. The ResNet50 \"application\" takes two key parameters here: firstly, `include_top` indicates whether we want to include the last layer of the network (the classification layer) or not. Secondly, `weights` indicates whether we want to load the weights of a model that has been pre-trained on ImageNet or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-qvHP-dI_fg",
    "outputId": "d90cccd8-6c3a-475b-ce8f-4856f8216d4c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c5pPZHOdI_fg",
    "outputId": "a8f31f06-f67f-445a-d432-809009cdd920"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "7aGFgPUPI_fg"
   },
   "source": [
    "### Classification of an image\n",
    "\n",
    "**Exercise**\n",
    "- Reshape the `laptop` image to the shape `(224, 224, 3)` using `resize` from `skimage.transform`\n",
    "- Use `preprocess_input` from `tensorflow.keras.applications.imagenet_utils` to preprocess the image\n",
    "- Use `predict` to classify the image\n",
    "\n",
    "Documentation for each method:\n",
    "- [resize](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize)\n",
    "- [preprocess_input](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/preprocess_input)\n",
    "- [predict](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlD7kIiPI_fk"
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "# Your code here\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "#plt.imshow(image);\n",
    "\n",
    "# Load the image\n",
    "img_path = 'images/laptop.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Reshape the image to (224, 224, 3) using resize from skimage.transform\n",
    "img_resized = resize(img_array, (224, 224, 3), anti_aliasing=True)\n",
    "\n",
    "# Preprocess the image using preprocess_input\n",
    "img_preprocessed = preprocess_input(np.expand_dims(img_resized, axis=0))\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "# Predict the class of the image\n",
    "predictions = model.predict(img_preprocessed)\n",
    "\n",
    "# Decode the predictions\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=3)\n",
    "\n",
    "# Print the predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n",
    "    print(f\"{i+1}: {label} ({score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "PkFrM1RDI_fk"
   },
   "source": [
    "##  Taking snapshots from the webcam\n",
    "\n",
    "For this section, we will take an image from your laptop webcam and classify it. If you feel uncomfortable doing this section, you can skip it and use a photo of your choice from the web instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGtK689OI_fk"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def camera_grab(camera_id=0, fallback_filename=None):\n",
    "    camera = cv2.VideoCapture(camera_id)\n",
    "    try:\n",
    "        # take 10 consecutive snapshots to let the camera automatically tune\n",
    "        # itself and hope that the contrast and lighting of the last snapshot\n",
    "        # is good enough.\n",
    "        for i in range(10):\n",
    "            snapshot_ok, image = camera.read()\n",
    "        if snapshot_ok:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            print(\"WARNING: could not access camera\")\n",
    "            if fallback_filename:\n",
    "                image = imread(fallback_filename)\n",
    "    finally:\n",
    "        camera.release()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dm8XOffqI_fk"
   },
   "outputs": [],
   "source": [
    "image = camera_grab(camera_id=0, fallback_filename='laptop.jpeg')\n",
    "plt.imshow(image)\n",
    "print(\"dtype: {}, shape: {}, range: {}\".format(\n",
    "    image.dtype, image.shape, (image.min(), image.max())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WoYrRIdEI_fk"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Apply the same preprocessing as before and classify the image. What are your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1pXoFQgI_fk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# Load the image\n",
    "img_path = 'images/conv.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "# Convert the image to a numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "# Print image details\n",
    "\n",
    "\n",
    "# Reshape the image to (224, 224, 3) using resize from skimage.transform\n",
    "img_resized = resize(img, (224, 224, 3), anti_aliasing=True)\n",
    "\n",
    "# Preprocess the image using preprocess_input\n",
    "img_preprocessed = preprocess_input(np.expand_dims(img_resized, axis=0))\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "# Predict the class of the image\n",
    "predictions = model.predict(img_preprocessed)\n",
    "\n",
    "# Decode the predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=3)\n",
    "\n",
    "# Print the predictions\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n",
    "    print(f\"{i+1}: {label} ({score:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
